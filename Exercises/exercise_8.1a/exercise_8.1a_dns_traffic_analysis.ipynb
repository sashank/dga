{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ea154a",
   "metadata": {},
   "source": [
    "# Exercise 8.1A: DNS Traffic Pattern Analysis\n",
    "\n",
    "**Course**: SS*/AIML* ZG567 - AI and ML Techniques in Cyber Security  \n",
    "**Module**: 08 - Domain Name Detection  \n",
    "**Type**: Analytical Exercise  \n",
    "**Duration**: 2-3 hours  \n",
    "**Difficulty**: Beginner-Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Scenario\n",
    "\n",
    "You are a junior SOC analyst at a mid-sized enterprise. Your SIEM has captured 24 hours of DNS queries from the corporate network. Your task is to **establish baseline patterns** for legitimate DNS traffic to prepare for anomaly detection.\n",
    "\n",
    "## ðŸ“‹ Learning Objectives\n",
    "\n",
    "- Understand DNS query structure and components\n",
    "- Identify characteristics of legitimate domain traffic\n",
    "- Establish baselines for anomaly detection\n",
    "- Recognize temporal patterns in network behavior\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24540e74",
   "metadata": {},
   "source": [
    "## Setup: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03811f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ac8a7",
   "metadata": {},
   "source": [
    "## Task 1: Load and Explore DNS Query Logs\n",
    "\n",
    "### 1.1 Generate Sample DNS Logs\n",
    "\n",
    "For this exercise, we'll generate synthetic DNS logs that simulate 24 hours of corporate network traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eadff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported type for timedelta hours component: numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m minute_offset = np.random.randint(\u001b[32m0\u001b[39m, \u001b[32m60\u001b[39m)\n\u001b[32m     26\u001b[39m second_offset = np.random.randint(\u001b[32m0\u001b[39m, \u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m timestamp = start_time + \u001b[43mtimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhours\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhour_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminutes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mminute_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43msecond_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Source IP: Simulate corporate network (10.0.0.0/8)\u001b[39;00m\n\u001b[32m     30\u001b[39m source_ip = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m10.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.random.randint(\u001b[32m1\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m255\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.random.randint(\u001b[32m1\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m255\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.random.randint(\u001b[32m1\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[32m255\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported type for timedelta hours component: numpy.int64"
     ]
    }
   ],
   "source": [
    "# Generate sample DNS logs (simulated corporate traffic)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Common legitimate domains\n",
    "legitimate_domains = [\n",
    "    'google.com', 'microsoft.com', 'amazon.com', 'facebook.com',\n",
    "    'twitter.com', 'linkedin.com', 'github.com', 'stackoverflow.com',\n",
    "    'office365.com', 'salesforce.com', 'zoom.us', 'slack.com',\n",
    "    'dropbox.com', 'atlassian.com', 'adobe.com', 'apple.com'\n",
    "]\n",
    "\n",
    "# Generate 10,000 DNS queries over 24 hours\n",
    "n_queries = 10000\n",
    "start_time = datetime(2026, 1, 30, 0, 0, 0)\n",
    "\n",
    "dns_logs = []\n",
    "for i in range(n_queries):\n",
    "    # Timestamp: More queries during business hours (8am-6pm)\n",
    "    hour_offset = np.random.choice(\n",
    "        range(24),\n",
    "        p=[0.02, 0.01, 0.01, 0.01, 0.01, 0.02, 0.03, 0.04,  # 0-7am (sum: 0.15)\n",
    "           0.08, 0.10, 0.09, 0.09, 0.10, 0.09, 0.08, 0.07,  # 8am-3pm (sum: 0.70)\n",
    "           0.05, 0.03, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01]  # 4pm-11pm (sum: 0.15)\n",
    "    )\n",
    "    minute_offset = np.random.randint(0, 60)\n",
    "    second_offset = np.random.randint(0, 60)\n",
    "    timestamp = start_time + timedelta(hours=int(hour_offset), minutes=int(minute_offset), seconds=int(second_offset))\n",
    "    \n",
    "    # Source IP: Simulate corporate network (10.0.0.0/8)\n",
    "    source_ip = f\"10.{np.random.randint(1, 255)}.{np.random.randint(1, 255)}.{np.random.randint(1, 255)}\"\n",
    "    \n",
    "    # Domain: Mostly legitimate with some random patterns\n",
    "    if np.random.random() < 0.95:  # 95% legitimate\n",
    "        domain = np.random.choice(legitimate_domains)\n",
    "    else:  # 5% suspicious patterns (for later analysis)\n",
    "        random_string = ''.join(np.random.choice(list('abcdefghijklmnopqrstuvwxyz0123456789'), \n",
    "                                                  size=np.random.randint(8, 15)))\n",
    "        domain = f\"{random_string}.com\"\n",
    "    \n",
    "    # Query type: Mostly A records\n",
    "    query_type = np.random.choice(['A', 'AAAA', 'CNAME', 'MX'], p=[0.70, 0.15, 0.10, 0.05])\n",
    "    \n",
    "    dns_logs.append({\n",
    "        'timestamp': timestamp,\n",
    "        'source_ip': source_ip,\n",
    "        'domain': domain,\n",
    "        'query_type': query_type\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(dns_logs)\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Generated {len(df):,} DNS queries\")\n",
    "print(f\"ðŸ“… Time range: {df['timestamp'].min()} to {df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb783c9b",
   "metadata": {},
   "source": [
    "### 1.2 Initial Data Exploration\n",
    "\n",
    "**TODO**: Explore the dataset structure and calculate basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d106870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 10 rows\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE DNS LOGS\")\n",
    "print(\"=\" * 80)\n",
    "display(df.head(10))\n",
    "\n",
    "# Dataset info\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "df.info()\n",
    "\n",
    "# TODO: Calculate summary statistics\n",
    "# Hint: Use df.describe() to get numeric summaries\n",
    "# Hint: Count unique domains, IPs, query types\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455d162",
   "metadata": {},
   "source": [
    "## Task 2: Domain Characteristic Analysis\n",
    "\n",
    "### 2.1 Extract Domain Components\n",
    "\n",
    "Parse domains to extract TLD, SLD, and other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_domain(domain):\n",
    "    \"\"\"\n",
    "    Extract components from domain name.\n",
    "    \n",
    "    Args:\n",
    "        domain (str): Domain name (e.g., 'www.example.com')\n",
    "        \n",
    "    Returns:\n",
    "        dict: Domain components\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = domain.split('.')\n",
    "        if len(parts) < 2:\n",
    "            return {'sld': domain, 'tld': None, 'subdomain_count': 0, 'length': len(domain)}\n",
    "        \n",
    "        tld = parts[-1]\n",
    "        sld = parts[-2] if len(parts) >= 2 else None\n",
    "        subdomain_count = len(parts) - 2 if len(parts) > 2 else 0\n",
    "        \n",
    "        return {\n",
    "            'sld': sld,\n",
    "            'tld': tld,\n",
    "            'subdomain_count': subdomain_count,\n",
    "            'length': len(sld) if sld else 0\n",
    "        }\n",
    "    except:\n",
    "        return {'sld': None, 'tld': None, 'subdomain_count': 0, 'length': 0}\n",
    "\n",
    "# Apply domain parsing\n",
    "domain_components = df['domain'].apply(parse_domain).apply(pd.Series)\n",
    "df = pd.concat([df, domain_components], axis=1)\n",
    "\n",
    "print(\"âœ… Domain components extracted\")\n",
    "display(df[['domain', 'sld', 'tld', 'subdomain_count', 'length']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334e1a6",
   "metadata": {},
   "source": [
    "### 2.2 Analyze TLD Distribution\n",
    "\n",
    "**TODO**: Analyze the distribution of Top-Level Domains (TLDs) in the traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count TLD occurrences and create visualization\n",
    "# Hint: Use df['tld'].value_counts()\n",
    "# Hint: Create a bar chart showing top 10 TLDs\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Example structure:\n",
    "# tld_counts = ...\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(...)\n",
    "# plt.title('TLD Distribution in DNS Traffic')\n",
    "# plt.xlabel('Top-Level Domain')\n",
    "# plt.ylabel('Number of Queries')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9622b7",
   "metadata": {},
   "source": [
    "### 2.3 Domain Length Analysis\n",
    "\n",
    "**TODO**: Analyze the distribution of domain lengths (SLD length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7935ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate length statistics and create histogram\n",
    "# Hint: df['length'].describe() for statistics\n",
    "# Hint: Use plt.hist() for distribution visualization\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"Domain Length Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "# Display mean, median, std, min, max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc2f94",
   "metadata": {},
   "source": [
    "### 2.4 Character Composition Analysis\n",
    "\n",
    "Analyze the ratio of digits vs. alphabetic characters in domain names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_character_composition(domain):\n",
    "    \"\"\"\n",
    "    Analyze character composition of domain SLD.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Character composition metrics\n",
    "    \"\"\"\n",
    "    sld = domain.split('.')[0] if '.' in domain else domain\n",
    "    \n",
    "    digit_count = sum(c.isdigit() for c in sld)\n",
    "    alpha_count = sum(c.isalpha() for c in sld)\n",
    "    total = len(sld)\n",
    "    \n",
    "    return {\n",
    "        'digit_ratio': digit_count / total if total > 0 else 0,\n",
    "        'alpha_ratio': alpha_count / total if total > 0 else 0,\n",
    "        'has_digits': digit_count > 0\n",
    "    }\n",
    "\n",
    "# Apply composition analysis\n",
    "char_comp = df['domain'].apply(analyze_character_composition).apply(pd.Series)\n",
    "df = pd.concat([df, char_comp], axis=1)\n",
    "\n",
    "# TODO: Visualize character composition\n",
    "# Create a scatter plot or box plot showing digit_ratio distribution\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e1c047",
   "metadata": {},
   "source": [
    "## Task 3: Temporal Pattern Analysis\n",
    "\n",
    "### 3.1 Queries by Hour of Day\n",
    "\n",
    "Analyze when DNS queries occur throughout the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour from timestamp\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "# TODO: Count queries per hour and visualize\n",
    "# Hint: df.groupby('hour').size()\n",
    "# Hint: Create a line plot showing query volume over 24 hours\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Example structure:\n",
    "# hourly_counts = df.groupby('hour').size()\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(hourly_counts.index, hourly_counts.values, marker='o', linewidth=2)\n",
    "# plt.title('DNS Query Volume by Hour of Day')\n",
    "# plt.xlabel('Hour (0-23)')\n",
    "# plt.ylabel('Number of Queries')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6dc24",
   "metadata": {},
   "source": [
    "### 3.2 Business Hours vs. Off-Hours Analysis\n",
    "\n",
    "**TODO**: Compare DNS patterns during business hours (8am-6pm) vs. off-hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f94eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define business hours\n",
    "def categorize_time(hour):\n",
    "    if 8 <= hour < 18:\n",
    "        return 'Business Hours'\n",
    "    else:\n",
    "        return 'Off-Hours'\n",
    "\n",
    "df['time_category'] = df['hour'].apply(categorize_time)\n",
    "\n",
    "# TODO: Compare statistics between business hours and off-hours\n",
    "# - Query volume\n",
    "# - Unique domains\n",
    "# - Query types distribution\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c399fd",
   "metadata": {},
   "source": [
    "## Task 4: Create Baseline Profile\n",
    "\n",
    "### 4.1 Calculate Baseline Statistics\n",
    "\n",
    "Document normal characteristics of legitimate DNS traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate comprehensive baseline statistics\n",
    "\n",
    "baseline_profile = {\n",
    "    'total_queries': len(df),\n",
    "    'unique_domains': df['domain'].nunique(),\n",
    "    'unique_source_ips': df['source_ip'].nunique(),\n",
    "    \n",
    "    # Domain length statistics\n",
    "    'avg_domain_length': df['length'].mean(),\n",
    "    'median_domain_length': df['length'].median(),\n",
    "    'std_domain_length': df['length'].std(),\n",
    "    \n",
    "    # TODO: Add more statistics:\n",
    "    # - Most common TLDs (top 5)\n",
    "    # - Average digit ratio\n",
    "    # - Business hours query percentage\n",
    "    # - Query type distribution\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE to add more statistics\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BASELINE PROFILE: LEGITIMATE DNS TRAFFIC\")\n",
    "print(\"=\" * 80)\n",
    "for key, value in baseline_profile.items():\n",
    "    print(f\"{key:30s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bfe70",
   "metadata": {},
   "source": [
    "### 4.2 Define Anomaly Detection Thresholds\n",
    "\n",
    "**TODO**: Based on baseline analysis, define thresholds for flagging suspicious domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define anomaly detection rules\n",
    "# Example thresholds (adjust based on your analysis):\n",
    "\n",
    "anomaly_thresholds = {\n",
    "    # Rule 1: Domain length\n",
    "    'max_normal_length': None,  # TODO: Calculate from baseline (e.g., mean + 2*std)\n",
    "    \n",
    "    # Rule 2: Digit ratio\n",
    "    'max_digit_ratio': None,  # TODO: Define threshold (e.g., 0.3)\n",
    "    \n",
    "    # Rule 3: Suspicious TLDs\n",
    "    'suspicious_tlds': ['.tk', '.ml', '.ga', '.cf', '.gq'],  # Free TLDs often abused\n",
    "    \n",
    "    # TODO: Add more rules:\n",
    "    # - Subdomain count threshold\n",
    "    # - Off-hours query volume threshold\n",
    "    # - Entropy threshold (if you calculate it)\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE to calculate threshold values\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANOMALY DETECTION THRESHOLDS\")\n",
    "print(\"=\" * 80)\n",
    "for key, value in anomaly_thresholds.items():\n",
    "    print(f\"{key:30s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d54ef9",
   "metadata": {},
   "source": [
    "### 4.3 Apply Anomaly Detection Rules\n",
    "\n",
    "Test your thresholds by flagging potentially suspicious domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6065d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement anomaly detection function\n",
    "\n",
    "def flag_suspicious_domain(row, thresholds):\n",
    "    \"\"\"\n",
    "    Flag domain as suspicious based on multiple rules.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_suspicious, reasons)\n",
    "    \"\"\"\n",
    "    reasons = []\n",
    "    \n",
    "    # TODO: Implement detection rules\n",
    "    # Check length, digit ratio, TLD, etc.\n",
    "    # Append reasons for each violated rule\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    is_suspicious = len(reasons) > 0\n",
    "    return is_suspicious, reasons\n",
    "\n",
    "# Apply detection\n",
    "# df['suspicious'], df['reasons'] = zip(*df.apply(lambda row: flag_suspicious_domain(row, anomaly_thresholds), axis=1))\n",
    "\n",
    "# Display flagged domains\n",
    "# suspicious_domains = df[df['suspicious']]\n",
    "# print(f\"\\nðŸš¨ Flagged {len(suspicious_domains)} suspicious domains ({len(suspicious_domains)/len(df)*100:.2f}%)\")\n",
    "# display(suspicious_domains[['domain', 'length', 'digit_ratio', 'tld', 'reasons']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910f56b",
   "metadata": {},
   "source": [
    "## Deliverable: Summary Report\n",
    "\n",
    "### Create a summary of your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate summary report\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DNS TRAFFIC BASELINE ANALYSIS - SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET OVERVIEW\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total DNS Queries: {len(df):,}\")\n",
    "print(f\"Unique Domains: {df['domain'].nunique():,}\")\n",
    "print(f\"Time Period: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "\n",
    "# TODO: Add more sections:\n",
    "# - DOMAIN CHARACTERISTICS\n",
    "# - TEMPORAL PATTERNS\n",
    "# - ANOMALY DETECTION RESULTS\n",
    "# - RECOMMENDATIONS\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f0be0",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Reflection Questions\n",
    "\n",
    "Answer these questions in markdown cells below:\n",
    "\n",
    "1. **What are the top 3 characteristics that distinguish legitimate domains in this dataset?**\n",
    "\n",
    "2. **How would your baseline change if you analyzed DNS traffic from a different organization (e.g., university vs. financial company)?**\n",
    "\n",
    "3. **What are the limitations of using static thresholds for anomaly detection?**\n",
    "\n",
    "4. **If you deployed this system in a real SOC, what additional features would you add?**\n",
    "\n",
    "---\n",
    "\n",
    "### YOUR ANSWERS HERE:\n",
    "\n",
    "**Answer 1:**\n",
    "\n",
    "*[Your answer here]*\n",
    "\n",
    "**Answer 2:**\n",
    "\n",
    "*[Your answer here]*\n",
    "\n",
    "**Answer 3:**\n",
    "\n",
    "*[Your answer here]*\n",
    "\n",
    "**Answer 4:**\n",
    "\n",
    "*[Your answer here]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab921a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Submission Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "\n",
    "- [ ] All code cells execute without errors\n",
    "- [ ] At least 5 visualizations created (TLD chart, length histogram, temporal plot, etc.)\n",
    "- [ ] Baseline statistics calculated and documented\n",
    "- [ ] Anomaly detection thresholds defined with justification\n",
    "- [ ] Reflection questions answered\n",
    "- [ ] Summary report generated\n",
    "- [ ] Code is well-commented\n",
    "\n",
    "---\n",
    "\n",
    "**Version**: 1.0  \n",
    "**Last Updated**: January 31, 2026  \n",
    "**Instructor Contact**: Via course forum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
